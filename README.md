# MoYun Blog 爬虫与展示系统

一个高效的博客爬虫和网站展示系统，专为抓取和展示博客文章而设计。

## ✨ 核心功能

### 🕷️ 智能爬虫
- **高性能爬取**: 多线程并发爬取，支持大规模数据抓取
- **智能解析**: 自动识别文章标题、内容、发布时间等关键信息
- **去重机制**: 自动检测并跳过已存在的文章
- **错误处理**: 完善的异常处理和重试机制
- **用户代理轮换**: 模拟真实浏览器访问，避免被封禁

### 🌐 Web展示界面
- **响应式设计**: 完美适配桌面和移动设备
- **无限滚动**: 流畅的文章加载体验
- **实时搜索**: 支持标题和内容的全文搜索
- **文章归档**: 按年月分类浏览文章
- **优雅UI**: 现代化的界面设计和动画效果

### 📊 数据管理
- **JSON存储**: 轻量级本地数据存储
- **分页支持**: 高效的大数据量分页处理
- **搜索功能**: 快速的文本搜索和过滤
- **统计信息**: 文章数量和分布统计

## 🛠️ 技术栈

- **后端**: Python 3.7+, Flask
- **前端**: HTML5, CSS3, JavaScript, Bootstrap 5
- **爬虫**: requests, BeautifulSoup4, lxml
- **数据存储**: JSON文件
- **并发处理**: Python threading

## 📋 系统要求

- Python 3.7 或更高版本
- 4GB+ 内存（推荐）
- 稳定的网络连接

## 🚀 快速开始

### 1. 安装依赖

```bash
pip install -r requirements.txt
```

### 2. 运行爬虫

```bash
python run.py
```

选择选项1开始爬取数据。

### 3. 启动Web服务

```bash
python app.py
```

访问 http://localhost:5000 查看博客展示界面。

## 📁 项目结构

## ⚙️ 配置说明

### 爬虫配置

在 `crawler.py` 中可以调整以下参数：

- `max_workers`: 并发线程数（默认5）
- `delay_range`: 请求间隔范围（默认1-3秒）
- `max_retries`: 最大重试次数（默认3）

### Web服务配置

在 `app.py` 中可以调整：

- `host`: 服务器地址（默认0.0.0.0）
- `port`: 服务器端口（默认5000）
- `debug`: 调试模式（默认True）

## 🎯 使用场景

- **个人博客备份**: 备份和迁移博客内容
- **内容聚合**: 收集多个博客的文章
- **数据分析**: 分析博客内容和趋势
- **离线阅读**: 本地保存文章供离线阅读

## 📝 注意事项

1. **遵守robots.txt**: 请确保遵守目标网站的爬虫协议
2. **合理频率**: 避免过于频繁的请求，以免对目标服务器造成压力
3. **法律合规**: 仅用于学习和个人用途，请遵守相关法律法规
4. **数据备份**: 定期备份 `blog_data.json` 文件

## 🔧 性能优化

- 使用SSD存储以提高I/O性能
- 根据网络状况调整并发数
- 定期清理无效数据
- 考虑使用数据库存储大量数据

## 📄 许可证

MIT License

## 📞 联系方式

如有问题或建议，欢迎提交Issue或Pull Request。